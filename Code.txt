import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras.utils import array_to_img
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import pennylane as qml
from pennylane.templates import RandomLayers
from PIL import UnidentifiedImageError, Image
from multiprocessing import Pool  # For parallel processing
import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")


# -------------------------------
# LOAD AND SPLIT DATASET
# -------------------------------
def load_images_from_folder(folder_path):
    """Load images and labels from a folder"""
    images = []
    labels = []
    class_names = sorted(os.listdir(folder_path))
    class_map = {class_name: i for i, class_name in enumerate(class_names)}

    for class_name in class_names:
        class_path = os.path.join(folder_path, class_name)
        if not os.path.isdir(class_path):  # Skip if it's not a directory
            continue
        
        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)
            if os.path.isfile(img_path) and img_path.endswith(('.png', '.jpg', '.jpeg')):  # Ensure it's a file
                img = load_img(img_path, target_size=IMG_SIZE, color_mode="grayscale")
                img_array = img_to_array(img) / 255.0  # Normalize pixels
                images.append(img_array)
                labels.append(class_map[class_name])

    return np.array(images), np.array(labels), class_names


# -------------------------------
# QUANTUM DEVICE & CIRCUIT
# -------------------------------
N_LAYERS = 1
N_WIRES = 2
dev = qml.device("default.qubit", wires=N_WIRES)
rand_params = np.random.uniform(high=2 * np.pi, size=(N_LAYERS, N_WIRES))

@qml.qnode(dev)
def quantum_circuit(inputs):
    """Quantum feature extraction"""
    for j in range(N_WIRES):
        qml.RY(np.pi * inputs[j], wires=j)
    RandomLayers(rand_params, wires=list(range(N_WIRES)))
    return [qml.expval(qml.PauliZ(j)) for j in range(N_WIRES)]

def quantum_convolution(image):
    """Apply quantum convolution (Quanvolution)"""
    out = np.zeros((14, 14, N_WIRES))
    for i in range(0, 28, 2):
        for j in range(0, 28, 2):
            region = [
                image[i, j, 0],
                image[i, j + 1, 0],
                image[i + 1, j, 0],
                image[i + 1, j + 1, 0]
            ]
            q_result = quantum_circuit(region)
            out[i // 2, j // 2, :] = q_result
    return out

def process_images_parallel(images):
    """Apply quantum convolution to images (with multiprocessing)"""
    with Pool(processes=4) as pool:
        return np.array(pool.map(quantum_convolution, images))

def plot_images(original, quantum, index=0, save_path=OUTPUT_DIR):
    """Save comparison images (original vs. quantum processed)"""
    os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist
    fig, axes = plt.subplots(1, 2, figsize=(8, 4))

    # Original Image
    axes[0].imshow(original[index].reshape(28, 28), cmap="gray")
    axes[0].set_title("Original Image")
    axes[0].axis("off")

    # Quantum Processed Image
    quantum_img = quantum[index].reshape(14, 14, N_WIRES).mean(axis=-1)  # Average over wires
    axes[1].imshow(quantum_img, cmap="inferno")
    axes[1].set_title("Quantum Processed")
    axes[1].axis("off")

    # Save the figure
    save_file = os.path.join(save_path, f"comparison_{index}.png")
    plt.savefig(save_file, bbox_inches="tight", dpi=300)
    plt.close(fig)  # Close the figure to free memory

# -------------------------------
# MAIN PROCESS
# -------------------------------
if __name__ == "__main__":
    print("Starting augmentation process...")

    # Perform data augmentation for each class if not done
    for class_name in os.listdir(ORIGINAL_DATA_PATH):
        class_dir = os.path.join(ORIGINAL_DATA_PATH, class_name)
        if not os.path.isdir(class_dir):
            continue
        
        # Create output class directory for augmented images
        output_class_dir = os.path.join(AUGMENTED_DATA_PATH, class_name)
        if not os.path.exists(output_class_dir):
            os.makedirs(output_class_dir)
        
        # Check if augmentation is needed
        if len(os.listdir(output_class_dir)) < TOTAL_IMAGES_PER_CLASS:
            print(f"Augmenting images for class: {class_name}")
            augment_and_save_images(class_dir, class_name, output_class_dir)
        else:
            print(f"Augmented images for {class_name} already exist. Skipping augmentation.")

    print(f"Data augmentation complete. Augmented images saved to: {AUGMENTED_DATA_PATH}")

    # Load dataset from augmented images
    images, labels, class_names = load_images_from_folder(AUGMENTED_DATA_PATH)
    num_classes = len(class_names)

    # Split into train and test
    train_images, test_images, train_labels, test_labels = train_test_split(
        images, labels, test_size=TEST_SPLIT, stratify=labels, random_state=42
    )

    # Reshape for compatibility
    train_images = train_images.reshape(-1, 28, 28, 1)
    test_images = test_images.reshape(-1, 28, 28, 1)

    # Apply quantum convolution to training and testing images
    print("Processing training images with quantum convolution...")
    q_train_images = process_images_parallel(train_images)

    print("Processing test images with quantum convolution...")
    q_test_images = process_images_parallel(test_images)

    # Save comparison images (original vs. quantum-processed)
    print("Saving comparison images (original vs. quantum processed)...")
    for i in range(5):
        plot_images(train_images, q_train_images, index=i)

    # Build CNN Model
    model = keras.Sequential([
        keras.layers.Conv2D(32, (3, 3), activation="relu", input_shape=(14, 14, N_WIRES)),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Conv2D(64, (3, 3), activation="relu"),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Flatten(),
        keras.layers.Dense(64, activation="relu"),
        keras.layers.Dense(num_classes, activation="softmax")
    ])

    # Compile model
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
        loss="sparse_categorical_crossentropy",
        metrics=["accuracy"]
    )

    # Train model
    print("Training model...")
    history = model.fit(
        q_train_images, train_labels,
        validation_data=(q_test_images, test_labels),
        epochs=10,
        batch_size=32,
        verbose=2
    )

    # Save model
    model.save(os.path.join(OUTPUT_DIR, "trained_model.h5"))
    print(f"Model saved to {os.path.join(OUTPUT_DIR, 'trained_model.h5')}")

    # Confusion Matrix
    y_pred = np.argmax(model.predict(q_test_images), axis=1)
    conf_matrix = confusion_matrix(test_labels, y_pred)

    # Save confusion matrix plot
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title("Confusion Matrix")
    confusion_matrix_save_path = os.path.join(OUTPUT_DIR, "confusion_matrix.png")
    plt.savefig(confusion_matrix_save_path, bbox_inches="tight", dpi=300)
    plt.close()
    print(f"Confusion matrix saved to {confusion_matrix_save_path}")

